{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#title           :fc_py3.ipynb\n",
    "#description     :This downloads future 5-day weather forecast, updating per 3 hours.\n",
    "#author          :Yuanyuan Zhao\n",
    "#date            :20181003\n",
    "#version         :3\n",
    "#notes           :\n",
    "#python_version  :3.6.4\n",
    "#==============================================================================\n",
    "\n",
    "from datetime import datetime, date, time, timedelta\n",
    "import time as t1\n",
    "import requests\n",
    "import bs4\n",
    "import json\n",
    "import yaml\n",
    "import csv\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrapes weather forecast data from openweathermap.org\n",
    "def spider(path):\n",
    "    \n",
    "    global fcResult \n",
    "    fcResult = []\n",
    "    locs = []\n",
    "#     reads in locations\n",
    "    with open(path, \"r\") as csvf:\n",
    "        dataReader = csv.reader(csvf)\n",
    "        for line in dataReader:\n",
    "            locs.append(line)\n",
    "            \n",
    "    for loc in locs:\n",
    "        url = \"http://api.openweathermap.org/data/2.5/forecast?lat=%s&lon=%s&APPID=ea4985020f724407dea8833c9dfee64c\"%(loc[0], loc[1])\n",
    "        response = requests.get(url)\n",
    "        json_data = yaml.load(json.dumps(response.json()))\n",
    "#         stores data in the following format: \n",
    "#         [dt, temp, pressure, humidity, temp_min, temp_max, wind_speed, clouds, weather_id, weather, description]\n",
    "        for x in json_data['list']:\n",
    "            weather_data = ((item[\"id\"], item[\"main\"], item[\"description\"]) for item in x[\"weather\"])\n",
    "            fcResult.append([datetime.utcfromtimestamp(int(x[\"dt\"])).strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                        x[\"main\"][\"temp\"],\n",
    "                        x[\"main\"][\"pressure\"],\n",
    "                        x[\"main\"][\"humidity\"],\n",
    "                        x[\"main\"][\"temp_min\"],\n",
    "                        x[\"main\"][\"temp_max\"],\n",
    "                        x[\"wind\"][\"speed\"],\n",
    "                        x[\"clouds\"][\"all\"],\n",
    "                        list(weather_data)\n",
    "                        ])\n",
    "    return fcResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processing of forecast weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary to map weather description information to input feature\n",
    "idf = open(\"idList.csv\",'r')\n",
    "ids = {}\n",
    "skip = True\n",
    "key = 0\n",
    "for line in idf:\n",
    "    if skip:\n",
    "        skip = False\n",
    "        continue\n",
    "    id = int(line.split(',')[0])\n",
    "    ids[id] = key\n",
    "    key += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#format of input weather data:\n",
    "#[dt, temp, pressure, humidity, temp_min, temp_max, wind_speed, clouds, weather_id, weather, description]\n",
    "#format of processed weather data:\n",
    "#[temp, temp_diff, pressure, humidity, wind_speed, clouds, bag of weather]\n",
    "def process(weather):\n",
    "    processing = []#store temporary processed weather data \n",
    "    processed = []#store processed weather data\n",
    "    time = []#store corresponding time of forecast weather data\n",
    "    \n",
    "    for i in range(40):#number of weather data for one location each call\n",
    "        time.append(weather[i][0])\n",
    "    \n",
    "    for i in range(len(weather)):\n",
    "        row = [float(weather[i][1]), float(weather[i][5])-float(weather[i][4]), float(weather[i][2]),\n",
    "               float(weather[i][3]),float(weather[i][6]),float(weather[i][7])]#first six features\n",
    "        bow = np.zeros(len(ids))#bag of weather feature\n",
    "        weatherdes = weather[i][8]\n",
    "        for j in range(len(weatherdes)):\n",
    "            wid = weatherdes[j][0]\n",
    "            bow[ids[wid]] = 1\n",
    "        processing.append(np.hstack([row, bow]))\n",
    "        \n",
    "    wnum = 40#number of weather data for one location each call\n",
    "    locnum = 10#number of location for each path\n",
    "    processing = np.array(processing)\n",
    "    for i in range(wnum):\n",
    "        weather1 = []#store the first six features of 10 locations\n",
    "        weather2 = []#store bag of weather feature of 10 locations\n",
    "        for j in range(locnum):\n",
    "            weather1.append(processing[i+40*j, :6])\n",
    "            weather2.append(processing[i+40*j, 6:])\n",
    "        processed.append(np.hstack([np.hstack(weather1), np.sum(weather2, axis=0)]))\n",
    "    return time, processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pre-trained model\n",
    "max_clf = joblib.load(\"max_clf.pkl\")#model predicting max drop rate\n",
    "mean_clf = joblib.load(\"mean_clf.pkl\")# model predicting mean drop rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2018-11-26 00:00:00', '2018-11-26 03:00:00', '2018-11-26 06:00:00', '2018-11-26 09:00:00', '2018-11-26 12:00:00', '2018-11-26 15:00:00', '2018-11-26 18:00:00', '2018-11-26 21:00:00', '2018-11-27 00:00:00', '2018-11-27 03:00:00', '2018-11-27 06:00:00', '2018-11-27 09:00:00', '2018-11-27 12:00:00', '2018-11-27 15:00:00', '2018-11-27 18:00:00', '2018-11-27 21:00:00', '2018-11-28 00:00:00', '2018-11-28 03:00:00', '2018-11-28 06:00:00', '2018-11-28 09:00:00', '2018-11-28 12:00:00', '2018-11-28 15:00:00', '2018-11-28 18:00:00', '2018-11-28 21:00:00', '2018-11-29 00:00:00', '2018-11-29 03:00:00', '2018-11-29 06:00:00', '2018-11-29 09:00:00', '2018-11-29 12:00:00', '2018-11-29 15:00:00', '2018-11-29 18:00:00', '2018-11-29 21:00:00', '2018-11-30 00:00:00', '2018-11-30 03:00:00', '2018-11-30 06:00:00', '2018-11-30 09:00:00', '2018-11-30 12:00:00', '2018-11-30 15:00:00', '2018-11-30 18:00:00', '2018-11-30 21:00:00']\n",
      "40 40\n",
      "[0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "#     forecast weather data for each path\n",
    "    fc_AUR02_CAR01 = spider('AUR02-CAR01.csv')\n",
    "    fc_CAR01_AUR02 = spider('CAR01-AUR02.csv')\n",
    "    fc_CHI01_AUR02 = spider('CHI01-AUR02.csv')\n",
    "    fc_AUR02_CHI01 = spider('AUR02-CHI01.csv')\n",
    "    fc_FRA01_SLO02 = spider('FRA01-SLO02.csv')\n",
    "    fc_SLO02_FRA01 = spider('SLO02-FRA01.csv')\n",
    "    fc_SEC10_TOR01 = spider('SEC10-TOR01.csv')\n",
    "    \n",
    "#     process weather data\n",
    "    time, input_AURCAR = process(fc_AUR02_CAR01)\n",
    "    input_CARAUR = process(fc_CAR01_AUR02)[1]\n",
    "    input_CHIAUR = process(fc_CHI01_AUR02)[1]\n",
    "    input_AURCHI = process(fc_AUR02_CHI01)[1]\n",
    "    input_FRASLO = process(fc_FRA01_SLO02)[1]\n",
    "    input_SLOFRA = process(fc_SLO02_FRA01)[1]\n",
    "    input_SECTOR = process(fc_SEC10_TOR01)[1]\n",
    "    \n",
    "#     predict max and mean drop rate\n",
    "    maxpred_AURCAR = max_clf.predict(input_AURCAR)\n",
    "    maxpred_CARAUR = max_clf.predict(input_CARAUR)\n",
    "    maxpred_CHIAUR = max_clf.predict(input_CHIAUR)\n",
    "    maxpred_AURCHI = max_clf.predict(input_AURCHI)\n",
    "    maxpred_FRASLO = max_clf.predict(input_FRASLO)\n",
    "    maxpred_SLOFRA = max_clf.predict(input_SLOFRA)\n",
    "    maxpred_SECTOR = max_clf.predict(input_SECTOR)\n",
    "    \n",
    "    meanpred_AURCAR = mean_clf.predict(input_AURCAR)\n",
    "    meanpred_CARAUR = mean_clf.predict(input_CARAUR)\n",
    "    meanpred_CHIAUR = mean_clf.predict(input_CHIAUR)\n",
    "    meanpred_AURCHI = mean_clf.predict(input_AURCHI)\n",
    "    meanpred_FRASLO = mean_clf.predict(input_FRASLO)\n",
    "    meanpred_SLOFRA = mean_clf.predict(input_SLOFRA)\n",
    "    meanpred_SECTOR = mean_clf.predict(input_SECTOR)\n",
    "    \n",
    "#     example of predicted label\n",
    "    print(time)#corresponding time of predicted drop rate\n",
    "    print(len(maxpred_AURCAR), len(meanpred_AURCAR))#there are 40 predictions for each path\n",
    "    print(maxpred_AURCAR)#predicted max drop rate for AUR02_CAR01\n",
    "#     you can use predicted results stored above to do visualization\n",
    "    \n",
    "    \n",
    "#     update every 3 hour\n",
    "    t1.sleep(60*60*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
